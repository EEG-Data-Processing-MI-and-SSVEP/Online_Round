{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-24T23:15:04.085068Z",
     "iopub.status.busy": "2025-06-24T23:15:04.084484Z",
     "iopub.status.idle": "2025-06-24T23:15:10.349015Z",
     "shell.execute_reply": "2025-06-24T23:15:10.348445Z",
     "shell.execute_reply.started": "2025-06-24T23:15:04.085045Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from scipy import signal\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T23:15:10.350632Z",
     "iopub.status.busy": "2025-06-24T23:15:10.350240Z",
     "iopub.status.idle": "2025-06-24T23:15:10.365200Z",
     "shell.execute_reply": "2025-06-24T23:15:10.364443Z",
     "shell.execute_reply.started": "2025-06-24T23:15:10.350605Z"
    }
   },
   "outputs": [],
   "source": [
    "class SSVEPDataset(Dataset):\n",
    "    \"\"\"Enhanced SSVEP dataset loader with frequency feature extraction\"\"\"\n",
    "    \n",
    "    # SSVEP frequencies for each class\n",
    "    FREQUENCIES = {\n",
    "        'Left': 10,\n",
    "        'Right': 13,\n",
    "        'Forward': 7,\n",
    "        'Backward': 8\n",
    "    }\n",
    "    \n",
    "    def __init__(self, csv_path, task='SSVEP', eeg_reference='average', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path: Path to metadata CSV\n",
    "            task: Task type (only SSVEP supported)\n",
    "            eeg_reference: Reference method for EEG\n",
    "            transform: Optional transforms to be applied\n",
    "        \"\"\"\n",
    "        self.base_path = '/kaggle/input/mtcaic3'\n",
    "        self.metadata = pd.read_csv(csv_path)\n",
    "        self.eeg_reference = eeg_reference\n",
    "        self.transform = transform\n",
    "        \n",
    "        if task:\n",
    "            self.metadata = self.metadata[self.metadata['task'] == task]\n",
    "            \n",
    "        # Create label encoding\n",
    "        print(sorted(self.FREQUENCIES.keys()))\n",
    "        self.classes = sorted(self.FREQUENCIES.keys())\n",
    "        self.label_encoding = {label: i for i, label in enumerate(self.classes)}\n",
    "        \n",
    "        # Precompute frequency bands of interest\n",
    "        self.freq_bands = {\n",
    "            label: (freq-1, freq+1) for label, freq in self.FREQUENCIES.items()\n",
    "        }\n",
    "        \n",
    "        # Sampling rate (Hz)\n",
    "        self.sfreq = 250\n",
    "        \n",
    "    def apply_reference(self, raw):\n",
    "        \"\"\"Apply EEG referencing\"\"\"\n",
    "        try:\n",
    "            if self.eeg_reference == 'average':\n",
    "                raw.set_eeg_reference('average', verbose=False)\n",
    "            elif self.eeg_reference in raw.ch_names:\n",
    "                raw.set_eeg_reference([self.eeg_reference], verbose=False)\n",
    "            elif self.eeg_reference is not None:\n",
    "                raise ValueError(f\"Invalid EEG reference: {self.eeg_reference}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"EEG referencing failed: {e}\")\n",
    "        return raw\n",
    "    \n",
    "    def extract_frequency_features(self, eeg_data):\n",
    "        \"\"\"Extract power in SSVEP frequency bands\"\"\"\n",
    "        n_channels, n_samples = eeg_data.shape\n",
    "        features = np.zeros((n_channels, len(self.freq_bands)))\n",
    "        \n",
    "        for i, (label, (low, high)) in enumerate(self.freq_bands.items()):\n",
    "            # Compute power spectral density using Welch's method\n",
    "            freqs, psd = signal.welch(eeg_data, fs=self.sfreq, nperseg=min(256, n_samples))\n",
    "            \n",
    "            # Find indices of frequency band\n",
    "            idx = np.logical_and(freqs >= low, freqs <= high)\n",
    "            \n",
    "            # Compute average power in band for each channel\n",
    "            features[:, i] = np.mean(psd[:, idx], axis=1)\n",
    "            \n",
    "        return features\n",
    "    \n",
    "    def normalize(self, data):\n",
    "        \"\"\"Normalize data channel-wise\"\"\"\n",
    "        mean = np.mean(data, axis=1, keepdims=True)\n",
    "        std = np.std(data, axis=1, keepdims=True)\n",
    "        return (data - mean) / (std + 1e-6)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.metadata.iloc[idx]\n",
    "        id_num = row['id']\n",
    "        dataset = 'train' if id_num <= 4800 else 'validation' if id_num <= 4900 else 'test'\n",
    "        \n",
    "        # Load EEG data\n",
    "        eeg_path = os.path.join(\n",
    "            self.base_path, row['task'], dataset,\n",
    "            row['subject_id'], str(row['trial_session']), \"EEGdata.csv\"\n",
    "        )\n",
    "        \n",
    "        df = pd.read_csv(eeg_path)\n",
    "        df[\"Time\"] -= df[\"Time\"].iloc[0]\n",
    "        \n",
    "        # Extract trial data\n",
    "        trial_num = int(row['trial'])\n",
    "        samples_per_trial = 1750\n",
    "        start_idx = (trial_num - 1) * samples_per_trial\n",
    "        end_idx = start_idx + samples_per_trial\n",
    "        df = df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        # EEG processing\n",
    "        eeg_channels = ['PO7', 'OZ', 'PO8']\n",
    "        if not all(ch in df.columns for ch in eeg_channels):\n",
    "            raise ValueError(f\"Missing required EEG channels in file: {eeg_path}\")\n",
    "        \n",
    "        eeg_data = df[eeg_channels].values.T\n",
    "        info = mne.create_info(ch_names=eeg_channels, sfreq=self.sfreq, ch_types='eeg')\n",
    "        raw = mne.io.RawArray(eeg_data, info, verbose=False)\n",
    "        \n",
    "        # Apply notch filter at 50Hz and bandpass filter in SSVEP range\n",
    "        raw.notch_filter(freqs=50, verbose=False)\n",
    "        raw.filter(l_freq=6, h_freq=30, verbose=False)  # Wider band to capture all frequencies\n",
    "        \n",
    "        # Apply referencing\n",
    "        raw = self.apply_reference(raw)\n",
    "        \n",
    "        # Get filtered data\n",
    "        eeg_filtered = raw.get_data()\n",
    "        \n",
    "        # Extract frequency features\n",
    "        freq_features = self.extract_frequency_features(eeg_filtered)\n",
    "        \n",
    "        # Normalize\n",
    "        eeg_normalized = self.normalize(eeg_filtered).astype(np.float32)\n",
    "        freq_features = self.normalize(freq_features).astype(np.float32)\n",
    "        \n",
    "        # Motion data\n",
    "        motion_channels = ['AccX', 'AccY', 'AccZ', 'Gyro1', 'Gyro2', 'Gyro3']\n",
    "        motion_data = df[motion_channels].values.T\n",
    "        motion_normalized = self.normalize(motion_data).astype(np.float32)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        eeg_tensor = torch.from_numpy(eeg_normalized)\n",
    "        freq_tensor = torch.from_numpy(freq_features)\n",
    "        motion_tensor = torch.from_numpy(motion_normalized)\n",
    "        label_tensor = torch.tensor(self.label_encoding[row['label']], dtype=torch.long)\n",
    "        \n",
    "        if self.transform:\n",
    "            eeg_tensor = self.transform(eeg_tensor)\n",
    "            \n",
    "        return eeg_tensor, freq_tensor, motion_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T23:15:10.366092Z",
     "iopub.status.busy": "2025-06-24T23:15:10.365901Z",
     "iopub.status.idle": "2025-06-24T23:15:10.398708Z",
     "shell.execute_reply": "2025-06-24T23:15:10.398061Z",
     "shell.execute_reply.started": "2025-06-24T23:15:10.366077Z"
    }
   },
   "outputs": [],
   "source": [
    "class EnhancedSSVEPModel(nn.Module):\n",
    "    \"\"\"Enhanced model for SSVEP classification with frequency attention\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=4, eeg_channels=3, motion_channels=6, freq_bands=4):\n",
    "        super(EnhancedSSVEPModel, self).__init__()\n",
    "        \n",
    "        # EEG branch - deeper architecture with residual connections\n",
    "        self.eeg_branch = nn.Sequential(\n",
    "            # First block\n",
    "            nn.Conv1d(eeg_channels, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool1d(2),  # 875\n",
    "            \n",
    "            # Second block with residual\n",
    "            ResidualBlock(64, 128, kernel_size=5, stride=2, downsample=True),  # 438\n",
    "            \n",
    "            # Third block\n",
    "            ResidualBlock(128, 256, kernel_size=5, stride=2, downsample=True),  # 219\n",
    "            \n",
    "            # Fourth block\n",
    "            ResidualBlock(256, 512, kernel_size=5, stride=2, downsample=True),  # 110\n",
    "            \n",
    "            # Attention pooling\n",
    "            AttentionPooling(512),\n",
    "            \n",
    "            # Final projection\n",
    "            nn.Linear(512, 256)\n",
    "        )\n",
    "        \n",
    "        # Rest of the model remains the same...\n",
    "        self.freq_branch = nn.Sequential(\n",
    "            nn.Linear(eeg_channels * freq_bands, 128),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64)\n",
    "        )\n",
    "        \n",
    "        self.motion_branch = nn.Sequential(\n",
    "            nn.Conv1d(motion_channels, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool1d(2),  # 875\n",
    "            \n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool1d(2),  # 438\n",
    "            \n",
    "            nn.Conv1d(64, 128, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ELU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 + 64 + 128, 512),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, eeg, freq, motion):\n",
    "        # EEG branch\n",
    "        eeg_features = self.eeg_branch(eeg)  # [B, 256]\n",
    "        \n",
    "        # Frequency branch\n",
    "        batch_size = freq.size(0)\n",
    "        freq_features = self.freq_branch(freq.view(batch_size, -1))  # [B, 64]\n",
    "        \n",
    "        # Motion branch\n",
    "        motion_features = self.motion_branch(motion).squeeze(-1)  # [B, 128]\n",
    "        \n",
    "        # Combine features\n",
    "        combined = torch.cat([eeg_features, freq_features, motion_features], dim=1)\n",
    "        logits = self.classifier(combined)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block with downsampling\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=5, stride=1, downsample=False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.downsample = downsample\n",
    "        \n",
    "        padding = kernel_size // 2\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, \n",
    "                             kernel_size=kernel_size, \n",
    "                             padding=padding, \n",
    "                             stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.elu = nn.ELU()\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, \n",
    "                             kernel_size=kernel_size, \n",
    "                             padding=padding)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        if downsample or in_channels != out_channels:\n",
    "            self.downsample_conv = nn.Conv1d(in_channels, out_channels, \n",
    "                                           kernel_size=1, \n",
    "                                           stride=stride)\n",
    "            self.downsample_bn = nn.BatchNorm1d(out_channels)\n",
    "        else:\n",
    "            self.downsample_conv = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.elu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample_conv is not None:\n",
    "            residual = self.downsample_conv(residual)\n",
    "            residual = self.downsample_bn(residual)\n",
    "            \n",
    "        out += residual\n",
    "        out = self.elu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    \"\"\"Attention-based temporal pooling\"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super(AttentionPooling, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv1d(channels, channels//8, kernel_size=1),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(channels//8, 1, kernel_size=1),\n",
    "            nn.Softmax(dim=2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [B, C, T]\n",
    "        weights = self.attention(x)  # [B, 1, T]\n",
    "        out = torch.sum(x * weights, dim=2)  # [B, C]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T23:15:10.400157Z",
     "iopub.status.busy": "2025-06-24T23:15:10.399969Z",
     "iopub.status.idle": "2025-06-24T23:15:10.419966Z",
     "shell.execute_reply": "2025-06-24T23:15:10.419368Z",
     "shell.execute_reply.started": "2025-06-24T23:15:10.400142Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=50, device='cuda'):\n",
    "    \"\"\"Enhanced training loop with comprehensive metrics tracking\"\"\"\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_f1': [],\n",
    "        'val_loss': [],\n",
    "        'val_f1': [],\n",
    "        'lr': []\n",
    "    }\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_f1   = 0\n",
    "    best_model_path = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        # Training phase with progress bar\n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        for eeg, freq, motion, labels in pbar:\n",
    "            eeg = eeg.to(device)\n",
    "            freq = freq.to(device)\n",
    "            motion = motion.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(eeg, freq, motion)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        # Calculate training metrics\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for eeg, freq, motion, labels in val_loader:\n",
    "                eeg = eeg.to(device)\n",
    "                freq = freq.to(device)\n",
    "                motion = motion.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(eeg, freq, motion)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "        \n",
    "        # Update learning rate\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step()\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Store history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_f1'].append(train_f1)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        history['lr'].append(current_lr)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f} | Train F1: {train_f1:.4f}\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f} | Val F1: {val_f1:.4f}\")\n",
    "        print(f\"  LR: {current_lr:.6f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if (val_f1 > best_f1) or (val_loss < best_loss):\n",
    "            if (val_f1 > best_f1):\n",
    "                best_f1   = val_f1\n",
    "            else:\n",
    "                best_loss = val_loss\n",
    "                \n",
    "            best_model_path = f'ssvep_model_epoch{epoch+1}_f1{val_f1:.4f}_loss{val_loss:.4f}.pth'\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_f1': val_f1,\n",
    "                'val_loss': val_loss,\n",
    "            }, best_model_path)\n",
    "            print(f\"  New best model saved: F1={best_f1:.4f} - Loss{best_loss:.4f}\")\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    return history, best_model_path\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # F1 score plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_f1'], label='Train F1')\n",
    "    plt.plot(history['val_f1'], label='Val F1')\n",
    "    plt.title('Training and Validation F1 Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T23:15:10.420952Z",
     "iopub.status.busy": "2025-06-24T23:15:10.420669Z",
     "iopub.status.idle": "2025-06-24T23:15:10.525083Z",
     "shell.execute_reply": "2025-06-24T23:15:10.524298Z",
     "shell.execute_reply.started": "2025-06-24T23:15:10.420928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Initialize device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Initialize datasets\n",
    "train_dataset = SSVEPDataset(\"/kaggle/input/mtcaic3/train.csv\", task='SSVEP')\n",
    "val_dataset = SSVEPDataset(\"/kaggle/input/mtcaic3/validation.csv\", task='SSVEP')\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T23:15:10.526104Z",
     "iopub.status.busy": "2025-06-24T23:15:10.525900Z",
     "iopub.status.idle": "2025-06-24T23:15:15.790928Z",
     "shell.execute_reply": "2025-06-24T23:15:15.790106Z",
     "shell.execute_reply.started": "2025-06-24T23:15:10.526088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 1750]) torch.Size([32, 3, 4]) torch.Size([32, 6, 1750]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data[0].shape, data[1].shape, data[2].shape, data[3].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T23:15:15.791846Z",
     "iopub.status.busy": "2025-06-24T23:15:15.791639Z",
     "iopub.status.idle": "2025-06-24T23:15:18.560096Z",
     "shell.execute_reply": "2025-06-24T23:15:18.559543Z",
     "shell.execute_reply.started": "2025-06-24T23:15:15.791831Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = EnhancedSSVEPModel(num_classes=4).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer with weight decay\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T23:15:18.561124Z",
     "iopub.status.busy": "2025-06-24T23:15:18.560786Z",
     "iopub.status.idle": "2025-06-24T23:15:18.565671Z",
     "shell.execute_reply": "2025-06-24T23:15:18.564980Z",
     "shell.execute_reply.started": "2025-06-24T23:15:18.561104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 3,350,949\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-25T01:47:27.845Z",
     "iopub.execute_input": "2025-06-24T23:15:18.566803Z",
     "iopub.status.busy": "2025-06-24T23:15:18.566537Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Train]: 100%|██████████| 75/75 [03:17<00:00,  2.64s/it, loss=1.2] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  Train Loss: 1.3328 | Train F1: 0.3541\n",
      "  Val Loss: 1.1829 | Val F1: 0.4131\n",
      "  LR: 0.001000\n",
      "  New best model saved: F1=0.4131 - Lossinf\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 [Train]: 100%|██████████| 75/75 [03:09<00:00,  2.53s/it, loss=1.28] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "  Train Loss: 1.2060 | Train F1: 0.4450\n",
      "  Val Loss: 1.1339 | Val F1: 0.4146\n",
      "  LR: 0.000999\n",
      "  New best model saved: F1=0.4146 - Lossinf\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 [Train]: 100%|██████████| 75/75 [03:14<00:00,  2.59s/it, loss=1.3]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "  Train Loss: 1.1825 | Train F1: 0.4638\n",
      "  Val Loss: 1.1816 | Val F1: 0.3593\n",
      "  LR: 0.000996\n",
      "  New best model saved: F1=0.4146 - Loss1.1816\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 [Train]: 100%|██████████| 75/75 [03:13<00:00,  2.57s/it, loss=1.21] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "  Train Loss: 1.1646 | Train F1: 0.4832\n",
      "  Val Loss: 1.0581 | Val F1: 0.4014\n",
      "  LR: 0.000991\n",
      "  New best model saved: F1=0.4146 - Loss1.0581\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 [Train]: 100%|██████████| 75/75 [03:12<00:00,  2.57s/it, loss=1.01] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "  Train Loss: 1.1450 | Train F1: 0.4993\n",
      "  Val Loss: 1.0687 | Val F1: 0.4287\n",
      "  LR: 0.000984\n",
      "  New best model saved: F1=0.4287 - Loss1.0581\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 [Train]: 100%|██████████| 75/75 [03:12<00:00,  2.57s/it, loss=1.37] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "  Train Loss: 1.1497 | Train F1: 0.4917\n",
      "  Val Loss: 1.0827 | Val F1: 0.3678\n",
      "  LR: 0.000976\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 [Train]: 100%|██████████| 75/75 [03:12<00:00,  2.56s/it, loss=1.05] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "  Train Loss: 1.1472 | Train F1: 0.4958\n",
      "  Val Loss: 1.0441 | Val F1: 0.3996\n",
      "  LR: 0.000965\n",
      "  New best model saved: F1=0.4287 - Loss1.0441\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 [Train]: 100%|██████████| 75/75 [03:12<00:00,  2.56s/it, loss=1.21] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "  Train Loss: 1.1432 | Train F1: 0.4984\n",
      "  Val Loss: 1.0629 | Val F1: 0.4058\n",
      "  LR: 0.000952\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 [Train]: 100%|██████████| 75/75 [03:12<00:00,  2.57s/it, loss=1.13] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "  Train Loss: 1.1288 | Train F1: 0.5003\n",
      "  Val Loss: 1.0491 | Val F1: 0.4772\n",
      "  LR: 0.000938\n",
      "  New best model saved: F1=0.4772 - Loss1.0441\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 [Train]: 100%|██████████| 75/75 [03:12<00:00,  2.56s/it, loss=1.19] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "  Train Loss: 1.1215 | Train F1: 0.5097\n",
      "  Val Loss: 1.0192 | Val F1: 0.5891\n",
      "  LR: 0.000922\n",
      "  New best model saved: F1=0.5891 - Loss1.0441\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 [Train]: 100%|██████████| 75/75 [03:11<00:00,  2.56s/it, loss=1.16] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "  Train Loss: 1.1243 | Train F1: 0.5093\n",
      "  Val Loss: 1.1203 | Val F1: 0.4553\n",
      "  LR: 0.000905\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 [Train]: 100%|██████████| 75/75 [03:11<00:00,  2.56s/it, loss=1.26] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "  Train Loss: 1.1111 | Train F1: 0.5084\n",
      "  Val Loss: 1.0172 | Val F1: 0.4993\n",
      "  LR: 0.000885\n",
      "  New best model saved: F1=0.5891 - Loss1.0172\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 [Train]: 100%|██████████| 75/75 [03:11<00:00,  2.55s/it, loss=1.14] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "  Train Loss: 1.1054 | Train F1: 0.5073\n",
      "  Val Loss: 1.0529 | Val F1: 0.4465\n",
      "  LR: 0.000864\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 [Train]: 100%|██████████| 75/75 [03:07<00:00,  2.50s/it, loss=1.18] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "  Train Loss: 1.0969 | Train F1: 0.5325\n",
      "  Val Loss: 1.0734 | Val F1: 0.5337\n",
      "  LR: 0.000842\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 [Train]: 100%|██████████| 75/75 [03:06<00:00,  2.49s/it, loss=1.01] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "  Train Loss: 1.0842 | Train F1: 0.5393\n",
      "  Val Loss: 1.0770 | Val F1: 0.6090\n",
      "  LR: 0.000819\n",
      "  New best model saved: F1=0.6090 - Loss1.0172\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 [Train]: 100%|██████████| 75/75 [03:07<00:00,  2.50s/it, loss=1.05] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "  Train Loss: 1.0924 | Train F1: 0.5290\n",
      "  Val Loss: 1.0719 | Val F1: 0.5183\n",
      "  LR: 0.000794\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 [Train]: 100%|██████████| 75/75 [03:06<00:00,  2.49s/it, loss=1.07] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "  Train Loss: 1.0770 | Train F1: 0.5286\n",
      "  Val Loss: 1.1284 | Val F1: 0.3912\n",
      "  LR: 0.000768\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 [Train]: 100%|██████████| 75/75 [03:07<00:00,  2.50s/it, loss=1.06] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "  Train Loss: 1.0613 | Train F1: 0.5462\n",
      "  Val Loss: 1.1256 | Val F1: 0.5401\n",
      "  LR: 0.000741\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 [Train]: 100%|██████████| 75/75 [03:07<00:00,  2.50s/it, loss=1.17] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "  Train Loss: 1.0531 | Train F1: 0.5454\n",
      "  Val Loss: 1.0811 | Val F1: 0.5233\n",
      "  LR: 0.000713\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 [Train]: 100%|██████████| 75/75 [03:07<00:00,  2.49s/it, loss=1.12] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "  Train Loss: 1.0513 | Train F1: 0.5475\n",
      "  Val Loss: 1.1510 | Val F1: 0.4878\n",
      "  LR: 0.000684\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 [Train]: 100%|██████████| 75/75 [03:08<00:00,  2.51s/it, loss=0.907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "  Train Loss: 1.0462 | Train F1: 0.5583\n",
      "  Val Loss: 1.0282 | Val F1: 0.5436\n",
      "  LR: 0.000655\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 [Train]: 100%|██████████| 75/75 [03:07<00:00,  2.50s/it, loss=1.08] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "  Train Loss: 1.0456 | Train F1: 0.5530\n",
      "  Val Loss: 1.0883 | Val F1: 0.5056\n",
      "  LR: 0.000624\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 [Train]: 100%|██████████| 75/75 [03:07<00:00,  2.51s/it, loss=0.964]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "  Train Loss: 1.0317 | Train F1: 0.5557\n",
      "  Val Loss: 1.1278 | Val F1: 0.4596\n",
      "  LR: 0.000594\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 [Train]: 100%|██████████| 75/75 [03:07<00:00,  2.51s/it, loss=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "  Train Loss: 1.0178 | Train F1: 0.5660\n",
      "  Val Loss: 1.0782 | Val F1: 0.5538\n",
      "  LR: 0.000563\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 [Train]: 100%|██████████| 75/75 [03:07<00:00,  2.51s/it, loss=0.926]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "  Train Loss: 1.0081 | Train F1: 0.5654\n",
      "  Val Loss: 1.1159 | Val F1: 0.5032\n",
      "  LR: 0.000531\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 [Train]: 100%|██████████| 75/75 [03:06<00:00,  2.48s/it, loss=1.17] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "  Train Loss: 1.0018 | Train F1: 0.5752\n",
      "  Val Loss: 1.1143 | Val F1: 0.5618\n",
      "  LR: 0.000500\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 [Train]: 100%|██████████| 75/75 [03:06<00:00,  2.49s/it, loss=0.834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "  Train Loss: 0.9999 | Train F1: 0.5728\n",
      "  Val Loss: 1.0497 | Val F1: 0.5203\n",
      "  LR: 0.000469\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 [Train]: 100%|██████████| 75/75 [03:06<00:00,  2.49s/it, loss=0.69] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "  Train Loss: 0.9767 | Train F1: 0.5808\n",
      "  Val Loss: 1.1456 | Val F1: 0.4960\n",
      "  LR: 0.000437\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 [Train]: 100%|██████████| 75/75 [03:10<00:00,  2.53s/it, loss=0.891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "  Train Loss: 0.9636 | Train F1: 0.6030\n",
      "  Val Loss: 1.1279 | Val F1: 0.5619\n",
      "  LR: 0.000406\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 [Train]: 100%|██████████| 75/75 [03:08<00:00,  2.51s/it, loss=0.827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "  Train Loss: 0.9569 | Train F1: 0.5860\n",
      "  Val Loss: 1.0830 | Val F1: 0.4956\n",
      "  LR: 0.000376\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 [Train]: 100%|██████████| 75/75 [03:07<00:00,  2.50s/it, loss=0.702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "  Train Loss: 0.9275 | Train F1: 0.6080\n",
      "  Val Loss: 1.2680 | Val F1: 0.5267\n",
      "  LR: 0.000345\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 [Train]: 100%|██████████| 75/75 [03:08<00:00,  2.51s/it, loss=0.969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "  Train Loss: 0.9284 | Train F1: 0.6207\n",
      "  Val Loss: 1.1345 | Val F1: 0.6003\n",
      "  LR: 0.000316\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 [Train]: 100%|██████████| 75/75 [03:08<00:00,  2.51s/it, loss=0.883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "  Train Loss: 0.9061 | Train F1: 0.6203\n",
      "  Val Loss: 1.0926 | Val F1: 0.6044\n",
      "  LR: 0.000287\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 [Train]: 100%|██████████| 75/75 [03:08<00:00,  2.51s/it, loss=0.758]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "  Train Loss: 0.8866 | Train F1: 0.6287\n",
      "  Val Loss: 1.1049 | Val F1: 0.6225\n",
      "  LR: 0.000259\n",
      "  New best model saved: F1=0.6225 - Loss1.0172\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 [Train]: 100%|██████████| 75/75 [03:07<00:00,  2.51s/it, loss=0.883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "  Train Loss: 0.8671 | Train F1: 0.6392\n",
      "  Val Loss: 1.1459 | Val F1: 0.5432\n",
      "  LR: 0.000232\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 [Train]: 100%|██████████| 75/75 [03:07<00:00,  2.50s/it, loss=0.717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "  Train Loss: 0.8387 | Train F1: 0.6508\n",
      "  Val Loss: 1.1558 | Val F1: 0.6023\n",
      "  LR: 0.000206\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 [Train]: 100%|██████████| 75/75 [03:14<00:00,  2.59s/it, loss=0.773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "  Train Loss: 0.8068 | Train F1: 0.6692\n",
      "  Val Loss: 1.3120 | Val F1: 0.4545\n",
      "  LR: 0.000181\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 [Train]: 100%|██████████| 75/75 [03:17<00:00,  2.64s/it, loss=0.824]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "  Train Loss: 0.8030 | Train F1: 0.6707\n",
      "  Val Loss: 1.2304 | Val F1: 0.5849\n",
      "  LR: 0.000158\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 [Train]: 100%|██████████| 75/75 [03:19<00:00,  2.65s/it, loss=0.582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "  Train Loss: 0.7506 | Train F1: 0.6954\n",
      "  Val Loss: 1.3039 | Val F1: 0.5657\n",
      "  LR: 0.000136\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 [Train]: 100%|██████████| 75/75 [03:18<00:00,  2.65s/it, loss=0.461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "  Train Loss: 0.7309 | Train F1: 0.7060\n",
      "  Val Loss: 1.3885 | Val F1: 0.4883\n",
      "  LR: 0.000115\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 [Train]: 100%|██████████| 75/75 [03:16<00:00,  2.62s/it, loss=0.57] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "  Train Loss: 0.7238 | Train F1: 0.7035\n",
      "  Val Loss: 1.3973 | Val F1: 0.5074\n",
      "  LR: 0.000095\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 [Train]: 100%|██████████| 75/75 [03:17<00:00,  2.63s/it, loss=0.8]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "  Train Loss: 0.6835 | Train F1: 0.7302\n",
      "  Val Loss: 1.4951 | Val F1: 0.5086\n",
      "  LR: 0.000078\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 [Train]: 100%|██████████| 75/75 [03:19<00:00,  2.66s/it, loss=0.433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "  Train Loss: 0.6532 | Train F1: 0.7409\n",
      "  Val Loss: 1.5605 | Val F1: 0.5025\n",
      "  LR: 0.000062\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 [Train]: 100%|██████████| 75/75 [03:20<00:00,  2.68s/it, loss=0.459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "  Train Loss: 0.6411 | Train F1: 0.7425\n",
      "  Val Loss: 1.5703 | Val F1: 0.5051\n",
      "  LR: 0.000048\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 [Train]: 100%|██████████| 75/75 [03:18<00:00,  2.65s/it, loss=0.61] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "  Train Loss: 0.6234 | Train F1: 0.7554\n",
      "  Val Loss: 1.6765 | Val F1: 0.4821\n",
      "  LR: 0.000035\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 [Train]: 100%|██████████| 75/75 [03:18<00:00,  2.64s/it, loss=0.543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "  Train Loss: 0.6112 | Train F1: 0.7553\n",
      "  Val Loss: 1.6251 | Val F1: 0.5231\n",
      "  LR: 0.000024\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 [Train]:  75%|███████▍  | 56/75 [02:29<00:50,  2.67s/it, loss=0.44] "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history, best_model_path = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-25T01:47:27.846Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12673416,
     "sourceId": 98188,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
