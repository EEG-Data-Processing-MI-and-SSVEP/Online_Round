{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import os, mne, torch\n",
    "import numpy as np\n",
    "from scipy.signal import welch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSVEPDataset(Dataset):\n",
    "    # SSVEP frequencies for each class\n",
    "    FREQUENCIES = {\n",
    "        'Left': 10,    # ---> 0\n",
    "        'Right': 13,   # ---> 1\n",
    "        'Forward': 7,  # ---> 2\n",
    "        'Backward': 8  # ---> 3\n",
    "    }\n",
    "    \n",
    "    def __init__(self, csv_metadata_path,\n",
    "                 task:str='SSVEP', \n",
    "                 eeg_reference='average',\n",
    "                 transform=None,\n",
    "                 fs=250 ,\n",
    "                 tmin=1,\n",
    "                 tmax=6,\n",
    "                 noise_margin=1, \n",
    "                 bandpass_band=(5,30),\n",
    "                 notch_freq=50,\n",
    "                 do_normalization=True,\n",
    "                 get_psd_plus_snr=True,\n",
    "                 noise_n_neighbor_freqs=3, \n",
    "                 noise_skip_neighbor_freqs=0\n",
    "                ):\n",
    "        \n",
    "        self.base_path = '.' \n",
    "\n",
    "        self.metadata = pd.read_csv(csv_metadata_path)\n",
    "        self.metadata = self.metadata[self.metadata['task'] == task] if task else self.metadata\n",
    "        self.eeg_reference = eeg_reference\n",
    "        self.transform = transform\n",
    "        self.sfreq = fs\n",
    "        self.tmin = tmin\n",
    "        self.tmax = tmax\n",
    "        self.bandpass_band = bandpass_band\n",
    "        self.notch_freq = notch_freq\n",
    "        self.do_normalization = do_normalization\n",
    "        self.get_psd_plus_snr = get_psd_plus_snr\n",
    "        self.noise_n_neighbor_freqs = noise_n_neighbor_freqs\n",
    "        self.noise_skip_neighbor_freqs = noise_skip_neighbor_freqs\n",
    "\n",
    "        self.label2idx = {label:i for i, (label,freq) in enumerate(self.FREQUENCIES.items())}\n",
    "        self.idx2label = {i:label for label,i in self.label2idx.items()}\n",
    "        \n",
    "        self.freq_bands = {label: (freq-noise_margin , freq+noise_margin) for label, freq in self.FREQUENCIES.items() }\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.metadata.iloc[index]\n",
    "        id_num = row['id']\n",
    "        split = 'train' if id_num <=4800 else 'validation' if id_num <=4900 else 'test'\n",
    "\n",
    "        eeg_path = os.path.join(\n",
    "              self.base_path, row['task'], split, row['subject_id'], str(row['trial_session']), 'EEGdata.csv'\n",
    "        )\n",
    "\n",
    "        ten_trials_df = pd.read_csv(eeg_path)\n",
    "        ten_trials_df['Time'] -= ten_trials_df['Time'].iloc[0]\n",
    "\n",
    "        trial_num = int(row['trial'])\n",
    "        samples_per_trial = 1750 if row['task'].lower() == 'ssvep' else 2250\n",
    "        one_trial_df = ten_trials_df.iloc[(trial_num-1)*samples_per_trial : trial_num*samples_per_trial] # shape(1750, 8ch+othercolumns)\n",
    "\n",
    "        ssvep_channels = ['PO7', 'OZ', 'PO8']\n",
    "        if not all(ch in one_trial_df.columns for ch in ssvep_channels):\n",
    "            raise ValueError(f\"Missing required EEG channels in file: {eeg_path}\")\n",
    "        \n",
    "        one_trial_array_ssvep_channels = one_trial_df[ssvep_channels].values.T # shape (3, 1750)\n",
    "\n",
    "        # normalizing \n",
    "        normalized_one_trial_array = self._normalize(one_trial_array_ssvep_channels) if self.do_normalization else one_trial_array_ssvep_channels\n",
    "        \n",
    "        info = mne.create_info(ch_names=ssvep_channels, sfreq=self.sfreq, ch_types='eeg')\n",
    "        raw = mne.io.RawArray(normalized_one_trial_array, info, verbose=False)\n",
    "        \n",
    "        # processing\n",
    "        raw = self._apply_reference(raw)\n",
    "        raw.notch_filter(freqs=self.notch_freq, verbose=False)\n",
    "        raw.filter(l_freq=self.bandpass_band[0], h_freq=self.bandpass_band[1], verbose=False)  # Wider band to capture all frequencies\n",
    "        \n",
    "        features_as_array = self._get_psds_pls_snrs_as_array(raw) if self.get_psd_plus_snr else raw.get_data()\n",
    "\n",
    "        X_trial = torch.FloatTensor(features_as_array)\n",
    "        Y_trial = torch.tensor(self.label2idx[row['label']], dtype=torch.long)\n",
    "        \n",
    "        return X_trial, Y_trial\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "    \n",
    "\n",
    "    def _apply_reference(self, raw):\n",
    "        try:\n",
    "            if self.eeg_reference == 'average':\n",
    "                raw.set_eeg_reference('average', verbose=False)\n",
    "            elif self.eeg_reference in raw.ch_names:\n",
    "                raw.set_eeg_reference([self.eeg_reference], verbose=False)\n",
    "            elif self.eeg_reference is not None:\n",
    "                raise ValueError(f\"Invalid EEG reference: {self.eeg_reference}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"EEG referencing failed: {e}\")\n",
    "        return raw\n",
    "    \n",
    "    def _normalize(self, data_array): # shape(3, 1750)\n",
    "        data_array-= np.mean(data_array, axis=1, keepdims=True)\n",
    "        return data_array/(np.std(data_array,axis=1, keepdims=True)+1e-9)\n",
    "    \n",
    "    def _snr_spectrum(self, psd):\n",
    "        \"\"\"Compute SNR spectrum from PSD spectrum using convolution\"\"\"\n",
    "        # Construct kernel for noise calculation\n",
    "        kernel = np.concatenate((\n",
    "            np.ones(self.noise_n_neighbor_freqs),\n",
    "            np.zeros(2 * self.noise_skip_neighbor_freqs + 1),\n",
    "            np.ones(self.noise_n_neighbor_freqs)\n",
    "        ))\n",
    "        kernel /= kernel.sum()\n",
    "        \n",
    "        # Calculate mean noise through convolution\n",
    "        mean_noise = np.convolve(psd, kernel, mode='valid')\n",
    "        \n",
    "        # Pad edges with NaNs\n",
    "        edge_width = self.noise_n_neighbor_freqs + self.noise_skip_neighbor_freqs\n",
    "        pad_width = [(edge_width, edge_width)]\n",
    "        mean_noise = np.pad(mean_noise, pad_width, constant_values=np.nan)\n",
    "        \n",
    "        return psd / mean_noise\n",
    "    \n",
    "    def _get_psds_pls_snrs_as_array(self, raw):\n",
    "        \n",
    "        data_array = raw.get_data()\n",
    "        \n",
    "        start_idx = int(self.tmin * self.sfreq)\n",
    "        end_idx = int(self.tmax * self.sfreq)\n",
    "        data_array = data_array[:, start_idx:end_idx]  # Shape: (n_channels, n_samples)\n",
    "        \n",
    "        # Compute features for each channel\n",
    "        features = []\n",
    "        for ch_data in data_array:\n",
    "            # Compute PSD using Welch's method\n",
    "            freqs, psd = welch(ch_data,\n",
    "                               fs=self.sfreq, \n",
    "                               window=\"boxcar\", \n",
    "                               nperseg=min(256, len(ch_data)),\n",
    "                               average='mean')\n",
    "            # Compute SNR spectrum\n",
    "            snr = self._snr_spectrum(psd)\n",
    "            # Extract features at target frequencies\n",
    "            freq_features = []\n",
    "            for freq in self.FREQUENCIES.values():\n",
    "                # Find closest frequency bin\n",
    "                idx = np.argmin(np.abs(freqs - freq))\n",
    "                freq_features.extend([\n",
    "                    psd[idx],      # PSD at target frequency\n",
    "                    snr[idx]       # SNR at target frequency\n",
    "                ])\n",
    "            features.extend(freq_features)\n",
    "        \n",
    "        # normalize features\n",
    "        features = np.array(features)\n",
    "        features-= np.mean(features,axis=-1, keepdims=True)\n",
    "        features/= (np.std(features,axis=-1, keepdims=True)+1e-9)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = SSVEPDataset('train.csv')\n",
    "x,y = d[0]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "dataloaders = {}\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    datasets[split] = SSVEPDataset(f'{split}.csv')\n",
    "    dataloaders[split] = DataLoader(datasets[split],\n",
    "                                    batch_size=64,\n",
    "                                    shuffle=(split=='train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dl, val_dl, model, optimizer, scheduler, criterion, num_epochs, lr):\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_f1': [],\n",
    "        'val_loss': [],\n",
    "        'val_f1': [],\n",
    "        'lr': []\n",
    "    }\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_model_path = None\n",
    "    best_f1_score = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0\n",
    "        all_train_preds = torch.tensor([], device=device)\n",
    "        all_train_labels = torch.tensor([], device=device)\n",
    "        tqdmbar =  tqdm(train_dl, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        for x,y in tqdmbar:\n",
    "            inputs = x.to(device)\n",
    "            targets = y.to(device)\n",
    "\n",
    "            # Reset the gradients (from the last iteration)\n",
    "            optimizer.zero_grad()\n",
    "            # Forward inference\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            # Backward propagation\n",
    "            loss.backward()\n",
    "            # Update optimizer and LR scheduler\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_loss += loss.item()\n",
    "            _, preds_indices = torch.max(outputs, 1)\n",
    "\n",
    "            all_train_preds = torch.cat((all_train_preds,preds_indices) )\n",
    "            all_train_labels = torch.cat((all_train_labels,targets))\n",
    "            tqdmbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        train_average_loss_per_batch = running_train_loss / len(train_dl)\n",
    "        train_f1_score = f1_score(all_train_labels.to('cpu'), all_train_preds.to('cpu'))\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        running_val_loss = 0\n",
    "        all_val_preds = torch.tensor([], device=device)\n",
    "        all_val_labels = torch.tensor([], device=device)\n",
    "        for x,y in val_dl:\n",
    "            inputs = x.to(device)\n",
    "            targets = y.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_val_loss += loss.item()\n",
    "            _, preds_indices = torch.max(outputs, 1)\n",
    "\n",
    "            all_val_preds = torch.cat((all_val_preds, preds_indices) )\n",
    "            all_val_labels = torch.cat((all_val_labels, targets))\n",
    "            \n",
    "        val_average_loss_per_batch = running_val_loss / len(val_dl)\n",
    "        val_f1_score = f1_score(all_val_labels.to('cpu'), all_val_preds.to('cpu'))\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step()\n",
    "\n",
    "        \n",
    "        # Store history\n",
    "        history['train_loss'].append(train_average_loss_per_batch)\n",
    "        history['train_f1'].append(train_f1_score)\n",
    "        history['val_loss'].append(val_average_loss_per_batch)\n",
    "        history['val_f1'].append(val_f1_score)\n",
    "        history['lr'].append(current_lr)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"  Train Loss: {train_average_loss_per_batch:.4f} | Train F1: {train_f1_score:.4f}\")\n",
    "        print(f\"  Val Loss: {val_average_loss_per_batch:.4f} | Val F1: {val_f1_score:.4f}\")\n",
    "        print(f\"  LR: {current_lr:.6f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if (val_f1_score > best_f1_score):\n",
    "            best_f1_score   = val_f1_score\n",
    "        elif(val_average_loss_per_batch < best_loss):\n",
    "            best_loss = val_average_loss_per_batch\n",
    "                \n",
    "            best_model_path = f'ssvep_model_epoch{epoch+1}_f1{val_f1_score:.4f}_loss{val_average_loss_per_batch:.4f}.pth'\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_f1': val_f1_score,\n",
    "                'val_loss': val_average_loss_per_batch,\n",
    "            }, best_model_path)\n",
    "            print(f\"  New best model saved: F1={best_f1_score:.4f} - Loss{best_loss:.4f}\")\n",
    "        \n",
    "        print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedSSVEPModel(nn.Module):\n",
    "    def __init__(self, num_classes=4, input_features=24):\n",
    "        \"\"\"\n",
    "        Enhanced SSVEP Classifier for PSD+SNR features (3 channels × 4 freqs × 2 features)\n",
    "        \n",
    "        Args:\n",
    "            num_classes: Number of SSVEP classes (default:4)\n",
    "            input_features: Should be 24 (3ch × 4freqs × [PSD,SNR])\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Feature processing branch\n",
    "        self.feature_processor = nn.Sequential(\n",
    "            nn.Linear(input_features, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ELU()\n",
    "        )\n",
    "        \n",
    "        # Attention mechanism for channel-frequency features\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # Final classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Frequency embedding (for 4 target frequencies)\n",
    "        self.freq_embedding = nn.Embedding(4, 32)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, 24) where 24 = 3ch × 4freqs × 2features\n",
    "        x = x.float()\n",
    "        # Process features\n",
    "        features = self.feature_processor(x)\n",
    "        \n",
    "        # Apply attention\n",
    "        attention_weights = self.attention(features)\n",
    "        weighted_features = attention_weights * features\n",
    "        \n",
    "        # Classify\n",
    "        logits = self.classifier(weighted_features)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "model = EnhancedSSVEPModel(num_classes=4).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer with weight decay\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "train_model(train_dl=dataloaders['trian'], \n",
    "            val_dl=dataloaders['val'], \n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            criterion=criterion,\n",
    "            num_epochs=50,\n",
    "            lr=1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
